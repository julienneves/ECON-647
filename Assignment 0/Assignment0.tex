%This is a LaTeX template for homework assignments
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,enumerate}
\usepackage[]{mcode}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath} \newenvironment{smatrix}{\left(\begin{smallmatrix}}{\end{smallmatrix}\right)}

\begin{document}

\section*{Assignment 0}
Name: Julien Neves\\
Name: Matthieu Ranger\\
Date: January 30, 2017

\subsection*{Problem 1}

\begin{equation}
\begin{smatrix} %explained vector
\Delta X_{t}^{1} \\ \Delta X_{t}^{2} \\ \Delta X_{t}^{3} \\ \Delta X_{t}^{4} \\ \Delta X_{t}^{5}
\end{smatrix}=
\begin{smatrix}  %ECT
-0.1938(0.0638)^{** } \\ -4.9\text{e-07}(3.6\text{e-07})^{    } \\ 0.0034(0.0028)^{    } \\  6.8\text{e-11}(2.1\text{e-10})^{    } \\ -1.0\text{e-07}(9.2\text{e-08})^{    }
\end{smatrix}ECT_{-1}
+\begin{smatrix}     %const
39818.9727(55318.0274)^{    } \\ 0.0987(0.3164)^{    } \\ 8186.2787(2393.3898)^{** } \\ 0.0002(0.0002)^{    } \\ 0.0785(0.0794)^{    }
\end{smatrix}+\begin{smatrix}     %trend
-315.5241(1069.6428)^{    } \\ 0.0033(0.0061)^{    } \\ -57.0145(46.2792)^{    } \\ -2.9\text{e-06}(3.5\text{e-06})^{    } \\ 0.0010(0.0015)^{    }
\end{smatrix}t
+\begin{smatrix}      %Lag1
0.4091(0.1198)^{** } & 22013.4782(22921.8274)^{    } & -0.9899(3.0099)^{    } & -26865556.7468(38911055.2208)^{    } & -115845.3660(93322.1406)^{    } \\
1.2\text{e-06}(6.9\text{e-07})^{.  } & -0.0489(0.1311)^{    } & -3.3\text{e-05}(1.7\text{e-05})^{.  } & -95.5560(222.5781)^{    } & -0.4228(0.5338)^{    } \\
-0.0068(0.0052)^{    } & -542.9386(991.7358)^{    } & 0.2893(0.1302)^{*  } & 2280021.4113(1683525.7349)^{    } & -8930.8623(4037.6758)^{*  } \\
-2.0\text{e-10}(3.9\text{e-10})^{    } & -3.5\text{e-05}(7.4\text{e-05})^{    } & -6.7\text{e-09}(9.8\text{e-09})^{    } & -0.0054(0.1261)^{    } &  8.8\text{e-05}(0.0003)^{    } \\
1.6\text{e-08}(1.7\text{e-07})^{    } & 0.0033(0.0329)^{    } & -1.7\text{e-05}(4.3\text{e-06})^{***} & -5.3850(55.8474)^{    } & -0.1597(0.1339)^{    } 
\end{smatrix}
\begin{smatrix}
\Delta X_{t-1}^{1} \\ \Delta X_{t-1}^{2} \\ \Delta X_{t-1}^{3} \\ \Delta X_{t-1}^{4} \\ \Delta X_{t-1}^{5}
\end{smatrix}
\end{equation}


\subsubsection*{4.1 - Derivative-Free Methods}

The naive idea is to "bracket around" the acceptable region in optimization. This type of method requires no derivatives of the objective function and is robust (guarantees success under wide conditions).

\textbf{Golden Search} is one example, where we pick values (two per dimension), split the "boxed interval" in two parts (per dimension) and repeat the procedure in the region where the function is evaluated to a greater value. 

Choosing a point to evaluate \textbf{F} is generally done by selecting $x_i = a + a_i (b-a)$ where 

$$ a_1 = \frac{3-\sqrt{5}}{2}$$ and $$a_2 = \frac{\sqrt{5} - 1}{2}$$

These values come from the criteria where the length of the new interval is independent of the lower or upper interval being chosen, and the ability to reuse interior points of previous iterations.

The \textbf{Nelder-Mead} method iterates over a simplex formed from the evaluation of \textbf{F} (starting with an initial guess). At each iteration, the point with the lowest value in the simplex (a corner) will reflect the opposite edge of the simplex (by twice the distance from the vertex to the opposing edge), prompting a search over the formed triangle outside the simplex for function values greater than ones in the simplex. If one is found, the simplex is expanded and we iterate.

If none are found, we contract the simplex by halving the distance between the point and its opposing edge, and shrink the simplex towards the best point if this new point is no better than the second worst. 

\subsubsection*{4.2 - Newton-Rhapson Method}

Newton-Raphson uses quadratic approximations of \textbf{F} to compute the root of the gradient (hence finding a max/minima). The updating rule is 

$$x^{(k+1)} \leftarrow x^{(k)} - [f''(x^{(k)})]^{-1}f'(x^{(k)}$$

which is a result from second order Taylor approximations of \textbf{F} at $x^{(k)}$, when solving the first order condition. Note that Newton-Raphson requires the function being twice differentiable (or double differentiation being numerically approximable, at least). The method is well-behaved on globally concave/vex functions, but may get stuck in "flat" areas if an initial guess is too far from a local max/minima. 

\subsubsection*{4.3 - Quasi-Newton Methods}


The Quasi-Newton methods employ the same strategy as the Newton method, but restrict the Hessian matrix to be Negative-definite approximation. This insures that the value function will increase at every step.

Like the Newton method, we get the that the direction we should take to optimize our function is given by
$$
d^{(k)}= - B^{(k)}f'(x^{(k)})
$$
where $B^{(k)}$ is the approximation to the Hessian $f'(x^{(k)})$ is the gradient evaluated at $x^{(k)}$.

Then, the updating of $x^{(k)}$ is given by the following formula.
$$
x^{(k+1)}= x^{(k)}-s^{(k)}d^{(k)}
$$
where $s^{(k)}$ is scaling factor for the $d^{(k)}$. If $B^{(k)}$ is the actual Hessian matrix and $s^{(k)}$ is set equal to one, it is easy to see that we are back at the original Netwon method.

Now, the choice of $B^{(k)}$ is important in terms of efficiency. The easiest choice for $B^{(k)}$ is to set it equal to the negative identity matrix $-I$. This insures the that $B^{(k)}$ is negative definite, but at the same time this is not the most optimal way to go about it. This choice of $B^{(k)}$ let's $d^{(k)}= f'(x^{(k)})$ which is the equivalent to having a Newton-step in the direction of the gradient. This method is now as the method of steepest ascent. 

Note that to satisfy the Quasi-Newton method, the matrix $B^{(k)}f'(x^{(k)})$ is require to satisfy two conditions:

\begin{enumerate}
\item Quasi-Newton Condition: 
$$
d^{(k)}= B^{(k+1)}[f'(x^{(k)}+d^{(k)})-f'(x^{(k)})]
$$
\item The inverse $B^{(k)}$ needs to be both symmetric and negative definite
\end{enumerate}

Two methods that satisfy this are the Davidon-Fletcher-Powell (DFP) and Broyden-Fletcher-Goldfard-Shano (BFGS) algorithms.

For the DFP algorithm, $B^{(k)}$ is updated in the following way:
$$
B^{(k+1)} = B^{(k)} + \frac{dd'}{d'u}-\frac{B^{(k)}dd'B^{(k)}}{u'B^{(k)}u}
$$
where $d=x^{(k+1)}-x^{(k)}$ and $u=f'(x^{(k+1)})-f'(x^{(k)})$ 

For the BFGS algorithm, $B^{(k)}$ is updated in the following way:
$$
B^{(k+1)} = B^{(k)} + \frac{1}{d'u}\left(wd'+dw'-\frac{w'u}{d'u}dd'\right)
$$
where $d=x^{(k+1)}-x^{(k)}$, $u=f'(x^{(k+1)})-f'(x^{(k)})$ and $w=d-B^{(k)}u$

BFGS is known to be superior to the DFP algorithm which both perfom better than the steepest ascent method usually.

One issue that the Quasi-Newton methods have is that due to the possible explosive nature of $\frac{1}{d'u}$. One way to prevent for this is to test that the following
$$
|d'u|< \epsilon ||d|| ||u||
$$
if it doesn't hold, we can either stop updating $B{(k)}$ or reset it to a negative identity matrix.
\subsubsection*{4.4 - Line Search Methods}

Like previously stated we might want to change our $s$ in our Quasi-Newton methods to improve our search. For example the golden search method is an example of linear search method.

Other example of linear search methods are for example the Armijo search and the Goldstein search.

For the Arminjo search, our goal is to find the minimum power of $j$ such that
$$
\frac{f(x+sd)-f(x)}{s}\geq \mu f'(x)^Td
$$
where $s=\rho^j$, $0<\rho <1$, and $0<\mu<0.5$. The basic goal is of this method is to start from a step-size of one, an backtrack until the slope on the lefthand side is a fraction $\mu$ of the slope on the righthand side.

For the Goldstein search, we find any values of $s$ such that
$$
\mu_0 f'(x)^Td \leq \frac{f(x+sd)-f(x)}{s}\leq \mu_1 f'(x)^Td
$$
for some values of $0<\mu_0\leq 0.5 \leq \mu_1 <0$. Note that in the case of Goldstein method, we only have a stopping rule and not a method of selecting candidates. 

One way to select a candidate $s$ in this case, is to double $s$ until we find a point that is such that it respect the Goldstein criterion or that is such that $
\mu_0 f'(x)^Td > \frac{f(x+sd)-f(x)}{s}
$ which we can then backtrack to a point that respect the criterion. 

Another method is to start with $s=1$ and $s$ is updated using the cubic approximation of the objective function until an appropriate point it found. Generaly this method will be fast, and better than other line search methods in most cases (especially if the function is smooth).

Finally the golden search, use the same procedure as described in $4.1$ to find an step size by setting a bracket of possible values of $s$ and reducing it until we are satisfied. 

\subsection*{Problem 2}

\subsubsection*{3.3}

\includegraphics[scale=0.7]{3_3}

On this figure, we see an example of the Cournot problem where $\eta=1.6$, $c_1=0.6$, and $c_2=0.8$. As we can see, the best response is that at the intersection of the reactions curves of both players. Using the Newton method and starting at $q_1=q_2=0.2$, it takes roughly three steps to reach the equilibrium. 

\subsubsection*{4.1}

\includegraphics[scale=0.7]{4_1}

Using golden search, we maximizes the function $x\cos (x^2)$. With this algorithm, we reach $x=0.8083$. It is straightforward to see that it is only a local maximum and not a global one. In fact, at $x=2.5$ we have a global maximum on $x=[0,3]$. This is problem arises from the fact that the optimand is not concave

\subsubsection*{4.3}

\includegraphics[scale=0.7]{4_3}

On this figure, we maximizes the banana function $f(x)=-100(x_2-x_1^2)^2-(1-x_1)^2$ using the Nelder-Mead algorithm. It reaches its stopping point at $x=(1,1)$ which is the global maximum. It takes the Nelder-Mead method 55 steps to reach this global maximum. The Nelder-Mead algorithm is based on evaluating the vertices of a simplex and then updating the simplex through reflection, expansion, contraction and shrinkage depending on the value of the vertices in order to converge to the maximum.
\clearpage

\appendix
\section*{Appendix - Code}

\lstinputlisting{demslv12.m}
\clearpage

\lstinputlisting{demopt01.m}
\clearpage

\lstinputlisting{demopt03.m}
\clearpage
\end{document}
